---
title: 'Practical Machine Learning - '
author: "Wiecher Olthof"
date: "July 10, 2018"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
  pdf_document:
    fig_caption: yes
    latex_engine: lualatex
    toc: yes
    toc_depth: 2
---
```{r  echo=FALSE, results="hide", include=FALSE }
rm(list=ls())
library(caret)
library(randomForest)
library(kernlab)
library(mlr)
library(corrplot)
library(rpart)
library(anchors)
library(dplyr)

set.seed(333)

## IMPORT TRAINING AND TESTING DATASETS
setwd("C:\\DataScience\\PracticalMachineLearning\\Week4\\Assignment\\data")
training <- read.csv(paste(getwd(), "\\pml-training.csv" ,sep=""), header=TRUE, sep=",", na.strings=c("#DIV/0!", NA), comment.char="", blank.lines.skip=TRUE, dec=".")
testing <- read.csv(paste(getwd(), "\\pml-testing.csv" ,sep=""), header=TRUE, sep=",", na.strings=c("#DIV/0!", NA), comment.char="", blank.lines.skip=TRUE, dec=".")

## SELECT ONLY VARIABLES ALSO PRESENT IN TESTING DATASET
## TRIED DOING THIS WITH NAMES BUT NOT SUCCEEDED
training <- select(training, c("num_window","roll_belt","pitch_belt","yaw_belt", "total_accel_belt", "gyros_belt_x","gyros_belt_y", "gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z","magnet_belt_x","magnet_belt_y","magnet_belt_z","roll_arm","pitch_arm","yaw_arm","total_accel_arm","gyros_arm_x","gyros_arm_y","gyros_arm_z","accel_arm_x","accel_arm_y","accel_arm_z", "magnet_arm_x","magnet_arm_y","magnet_arm_z","roll_dumbbell","pitch_dumbbell","yaw_dumbbell","total_accel_dumbbell","gyros_dumbbell_x","gyros_dumbbell_y","gyros_dumbbell_z","accel_dumbbell_x","accel_dumbbell_y", "accel_dumbbell_z","magnet_dumbbell_x","magnet_dumbbell_y","magnet_dumbbell_z","roll_forearm","pitch_forearm","yaw_forearm","total_accel_forearm","gyros_forearm_x","gyros_forearm_y","gyros_forearm_z", "accel_forearm_x" ,"accel_forearm_y","accel_forearm_z","magnet_forearm_x","magnet_forearm_y","magnet_forearm_z", "classe"))
print(names(training))

## CLEAN TRAINING AND TESTING DATASET
training <- training[colSums(!is.na(training)) > 0]
testing <- testing[colSums(!is.na(testing)) > 0]

## 2) REMOVE COLUMNS WITH NEAR ZERO VARIANCE
## None of the selected columns has zero or near-zero variance. Therefore select on percentage uniqueness (> 1)
nearzero <- nearZeroVar(training, saveMetrics=TRUE)

## Keep classe variable with percentUnique of 0.0254816
training <- training[, -which(nearzero$percentUnique < 1 & nearzero$percentUnique > 0.03)]

## 3) FIND PREDICTORS THAT ARE HIGHLY CORRELATED AND REMOVE ONE FROM EACH PAIR
trainingCorr <- sapply(training, as.numeric)
fullCorrMatrix <- abs(cor(trainingCorr))
diag(fullCorrMatrix) <- 0
corrplot(fullCorrMatrix)

## CREATE FORMULA USING SELECTED PREDICTORS
predictors <- names(training)
tries <- ncol(training) 
print(tries)

##print(names(training))
##print(names(testing))

 ## MODEL CREATION
mtryParam <- expand.grid(mtry=tries)
train_control <- trainControl(method="repeatedcv", number=5, repeats=1, allowParallel=TRUE)
fit <- caret::train(classe ~ ., data=training, method="rf", trControl=train_control, na.action=na.omit)

## PREDICTION
prediction <- predict(fit, newdata=testing, na.action=na.exclude)

varImp(fit)
```

## Executive summary
Tracking physical activity is becoming increasingly popular. Many devices are available for this purpose and
mostly used to measure the frequency of the exercise. This study aims to predict **how well** barr bell lifts are performed given a certain set of predictors. The predictors are a set of measurements recorded by tracking devices.

The training dataset consists of measurements from activity tracking devices of six persons who performed the Unilateral Dumbbell Biceps Curl 10 times in the following ways: **A)** Exactly according to the specification, **B)** Throwing the elbows to the front, **C)** Lifting the dumbbell only halfway, **D)** Lowering the dumbbell only halfway, **E)** Throwing the hips to the front. The categories A, B, C, D, E thus describe how well the exercise was performed. The testing dataset contains 20 test cases of which the model should predict the outcome (category A, B, C, D, E) using a number of selected predictors.*[2]* 

A cross-validated random forest model was used to predict the outcome and yielded an accuracy of > 99%. The outcome of the model using the test dataset was predicted correctly. The results were validated using the *Course Project Prediction Quiz* on Coursera.


## 1 Exploratory data analysis and cleaning
Analysis of the raw test- and training datasets showed that the two datasets were not compatible and some cleaning action was required. The test dataset contained less columns than the training dataset and thus it was possible that a selected predictor from the training dataset could in fact not be used for prediction based on the test dataset. A selection of the available predictors was made based on the columns in the test dataset.

Next, the correlation between the selected predictors was analyzed (below). Indeed, some predictors are highly correlated while others are not. However, no predictors were discarded based on their high correlation and therefore the impact on, for instance, processing time was not analyzed.


```{r  echo=FALSE, fig.width=8, fig.height=8}
 corrplot(fullCorrMatrix, tl.col="black")
```

None of the initially selected 53 predictors had zero or near-zero variance. However, nine of the selected predictors had a percentage of uniqueness smaller than 1% and were discarded. The 1% value was chosen arbitrarily and causes nine predictors with the smallest variances to be removed. Finally, 44 predictors with > 1% uniqueness remain which were used in the final Random Forest model


## 2 The Random Forest model
The aim of the model is to determine the score (A, B, C, D, E) that classifies how well a certain exercise is performed based on a number of predictors. The random forest model was selected for this purpose as it is useful for categorizing data. The model was built using the *train* function in the R-package Caret and tuned using its parameters.

```{r  echo=TRUE}
## mtryParam <- expand.grid(mtry=tries)
## train_control <- trainControl(method="repeatedcv", number=5, repeats=1, allowParallel=TRUE)
## fit <- caret::train(classe ~ ., data=training, method="rf", trControl=train_control, na.action=na.omit)
```

```{r  echo=FALSE}
 print(fit)
```


## 3 Cross validation
K-fold cross-validation (CV) was performed during the creation of the random forest model.
A random forest model was created four times with different K-values and repeats as specified below.

1) k=10, repeats=1
2) k=5, repeats=1
3) k=5, repeats=2
4) k=2, repeats1

All four methods yield an accuracy of > 99%.

The model using a *5-fold CV repeated one time* was used as the final model to predict the outcome using the test dataset. This choice is based on a trade off between processing time and the loss of accuracy.
A *2-fold CV repeated one time* yields a slightly lower accuracy but takes less processing time. 
A *5-fold CV repeated two times* yields a slightly higher accuracy but takes more processing time.

## 3 Results
After the creation of the final random forest model it was used to predict the outcome of the 20 testcases.

```{r  echo=FALSE}
 print(prediction)
## print(rmse(training$classe, prediction))
## confusionMatrix(prediction, training$classe)
 ##print(prediction$results)
```

The selected model yielded an accuracy of > 99% and predicted all values correctly, as shown above.

The *varImp* function in the Caret package determined that the variable *num_window* was the most important variable when predicting the *classe* variable. In addition, *roll_belt* and *pitch_forearm* were determined second and third most important variables, respectively. Alternatively, when *num_window* is not used as a predictor the model accuracy is still > 99%  

The out of sample error describes the error when the model is used on an independent dataset. In this case there were no prediction errors and the out of sample error should be close to zero.

## 4 Conclusion
The random forest model created for this study is very well capable of predicting in which manner (A, B, C, D, E) an exercise is performed for the 20 test cases, based on a wide range of measurements from six activity tracking devices. However, only 20 outcomes were predicted by the random forest model. How well the model performs when it comes to predicting more test cases is unknown. Moreover, the number of predictors may be reduced based on the correlation found between a number of pairs to make the random forest model more efficient. Further analysis is thus required. 

## Citations

[1] 
*Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.* 

[2] 
https://www.coursera.org/learn/practical-machine-learning/supplement/PvInj/course-project-instructions-read-first

[3]
http://www.cookbook-r.com


## Appendices

Correlation Matrix
```{r echo = FALSE, fig.width=8, fig.height=8}
  corrplot(fullCorrMatrix, tl.col="black")
```